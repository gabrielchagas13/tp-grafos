# README T√©cnico - Documenta√ß√£o do C√≥digo

## üìã Vis√£o Geral

Este projeto implementa uma an√°lise completa de grafos de colabora√ß√£o em reposit√≥rios GitHub usando Python. O sistema extrai dados da API do GitHub, modela diferentes tipos de intera√ß√µes como grafos direcionados, e gera visualiza√ß√µes e m√©tricas de centralidade.

## üèóÔ∏è Arquitetura do Sistema

```
etapa01/
‚îú‚îÄ‚îÄ src/                        # C√≥digo fonte principal
‚îÇ   ‚îú‚îÄ‚îÄ github_extractor.py     # Extra√ß√£o de dados da API GitHub
‚îÇ   ‚îú‚îÄ‚îÄ graph_models.py         # Classes de modelagem de grafos
‚îÇ   ‚îú‚îÄ‚îÄ graph_builder.py        # Constru√ß√£o e an√°lise dos grafos
‚îÇ   ‚îî‚îÄ‚îÄ graph_visualizer.py     # Visualiza√ß√µes e dashboards
‚îú‚îÄ‚îÄ data/                       # Dados extra√≠dos (CSV)
‚îú‚îÄ‚îÄ output/                     # Resultados e visualiza√ß√µes
‚îú‚îÄ‚îÄ main.py                     # Script principal
‚îú‚îÄ‚îÄ complete_extraction.py      # Script auxiliar de extra√ß√£o
‚îú‚îÄ‚îÄ generate_sample_data.py     # Gerador de dados simulados
‚îî‚îÄ‚îÄ check_rate_limit.py         # Verificador de rate limit
```

---

## üìö Bibliotecas e Depend√™ncias

### **Core Dependencies**

```python
import requests           # HTTP requests para API GitHub
import pandas as pd       # Manipula√ß√£o de dados estruturados
import networkx as nx     # An√°lise e manipula√ß√£o de grafos
import numpy as np        # Computa√ß√£o num√©rica
```

### **Visualiza√ß√£o**

```python
import matplotlib.pyplot as plt  # Gr√°ficos est√°ticos
import seaborn as sns            # Visualiza√ß√µes estat√≠sticas
import plotly.graph_objects as go # Gr√°ficos interativos
import plotly.express as px      # Gr√°ficos expressos
```

### **Utilidades**

```python
import json              # Serializa√ß√£o JSON
import time              # Controle de tempo e delays
import os                # Opera√ß√µes do sistema operacional
from datetime import datetime    # Manipula√ß√£o de datas
from typing import Dict, List, Optional  # Type hints
from tqdm import tqdm            # Barras de progresso
from dotenv import load_dotenv   # Carregamento de vari√°veis de ambiente
from collections import defaultdict  # Dicion√°rios com valores padr√£o
```

---

## üîß M√≥dulos Principais

### **1. github_extractor.py**

**Responsabilidade**: Extra√ß√£o de dados da API REST do GitHub

#### **Classe GitHubDataExtractor**

```python
class GitHubDataExtractor:
    def __init__(self, repo_owner: str, repo_name: str, token: Optional[str] = None)
```

**Principais M√©todos:**

- **`_make_request()`**: Executa requisi√ß√µes HTTP com tratamento de rate limit
- **`_paginate_request()`**: Gerencia pagina√ß√£o autom√°tica da API
- **`extract_issues()`**: Extrai issues do reposit√≥rio
- **`extract_pull_requests()`**: Extrai pull requests
- **`extract_issue_comments()`**: Extrai coment√°rios de issues espec√≠ficas
- **`extract_pr_reviews()`**: Extrai reviews de PRs
- **`extract_pr_comments()`**: Extrai coment√°rios de PRs
- **`extract_all_data()`**: Orquestra extra√ß√£o completa

**Funcionalidades T√©cnicas:**

1. **Rate Limiting**: Detecta e aguarda reset do rate limit automaticamente
2. **Pagina√ß√£o**: Coleta todos os dados usando pagina√ß√£o da API
3. **Error Handling**: Tratamento robusto de erros HTTP
4. **Data Persistence**: Salva dados em CSV para reutiliza√ß√£o

```python
# Exemplo de uso do rate limiting
if response.status_code == 403 and 'rate limit' in response.text.lower():
    reset_time = int(response.headers.get('X-RateLimit-Reset', 0))
    wait_time = max(0, reset_time - int(time.time()) + 1)
    time.sleep(wait_time)
```

### **2. graph_models.py**

**Responsabilidade**: Modelagem matem√°tica dos grafos de colabora√ß√£o

#### **Classes Principais:**

**CollaborationNode**: Representa usu√°rios (v√©rtices)
```python
class CollaborationNode:
    def __init__(self, username: str):
        self.username = username
        self.metrics = {
            "total_interactions": 0,
            "comments_made": 0,
            "issues_closed": 0,
            "reviews_given": 0,
            "prs_merged": 0,
            "centrality_score": 0.0
        }
```

**CollaborationEdge**: Representa intera√ß√µes (arestas)
```python
class CollaborationEdge:
    def __init__(self, source: str, target: str, interaction_type: str, weight: int = 1):
        self.source = source
        self.target = target
        self.interaction_type = interaction_type
        self.weight = weight
```

**CollaborationGraph**: Classe base para grafos direcionados
```python
class CollaborationGraph:
    def __init__(self, name: str):
        self.name = name
        self.graph = nx.DiGraph()  # Grafo direcionado NetworkX
        self.nodes = {}            # Dicion√°rio de n√≥s
        self.edges = {}            # Dicion√°rio de arestas
```

#### **Grafos Especializados:**

**1. CommentGraph**: Grafo de coment√°rios
- **Arestas**: comentarista ‚Üí autor da issue/PR
- **Pesos**: 2 (coment√°rios em PR), 3 (coment√°rios em issues)

**2. IssueCloseGraph**: Grafo de fechamento de issues
- **Arestas**: closer ‚Üí author
- **Peso**: 3

**3. ReviewGraph**: Grafo de reviews e merges
- **Arestas**: reviewer/merger ‚Üí author
- **Pesos**: 4 (review), 5 (merge)

**4. IntegratedGraph**: Grafo consolidado
- **Combina**: Todos os tipos de intera√ß√£o
- **Pesos ponderados**: Baseados na import√¢ncia da intera√ß√£o

#### **M√©tricas de Centralidade Implementadas:**

```python
def calculate_centrality_metrics(self):
    # Centralidade de grau (in/out)
    in_degree_centrality = nx.in_degree_centrality(self.graph)
    out_degree_centrality = nx.out_degree_centrality(self.graph)
    
    # Centralidade de proximidade
    closeness_centrality = nx.closeness_centrality(self.graph)
    
    # Centralidade de intermedia√ß√£o
    betweenness_centrality = nx.betweenness_centrality(self.graph)
    
    # PageRank
    pagerank = nx.pagerank(self.graph)
```

### **3. graph_builder.py**

**Responsabilidade**: Orquestra√ß√£o da constru√ß√£o e an√°lise dos grafos

#### **Classe GraphBuilder**

**Principais M√©todos:**

- **`load_data_from_csv()`**: Carrega dados de arquivos CSV existentes
- **`extract_and_load_data()`**: Extrai novos dados via API
- **`build_all_graphs()`**: Constr√≥i todos os 4 tipos de grafo
- **`export_all_graphs()`**: Exporta grafos em JSON e GEXF
- **`generate_report()`**: Gera relat√≥rio completo de an√°lise
- **`print_summary()`**: Exibe resumo no console

**Fluxo de Processamento:**

1. **Carregamento**: Dados ‚Üí DataFrames pandas
2. **Constru√ß√£o**: DataFrames ‚Üí Grafos NetworkX
3. **An√°lise**: C√°lculo de m√©tricas de centralidade
4. **Exporta√ß√£o**: Grafos ‚Üí JSON/GEXF para Gephi
5. **Relat√≥rio**: Estat√≠sticas ‚Üí JSON estruturado

### **4. graph_visualizer.py**

**Responsabilidade**: Visualiza√ß√£o e an√°lise visual dos grafos

#### **Classe GraphVisualizer**

**Tipos de Visualiza√ß√£o:**

**1. Grafos Est√°ticos (Matplotlib + Seaborn)**
```python
def plot_graph_basic(self, graph: CollaborationGraph):
    # Layout spring para posicionamento
    pos = nx.spring_layout(subgraph, k=1, iterations=50)
    
    # Tamanho baseado no grau
    node_sizes = [degrees[node] * 20 for node in subgraph.nodes()]
    
    # Cor baseada na centralidade
    node_colors = [centralities[node] for node in subgraph.nodes()]
```

**2. Grafos Interativos (Plotly)**
```python
def plot_interactive_graph(self, graph: CollaborationGraph):
    # Traces para arestas e n√≥s
    edge_trace = go.Scatter(x=edge_x, y=edge_y, mode='lines')
    node_trace = go.Scatter(x=node_x, y=node_y, mode='markers+text')
```

**3. An√°lises Comparativas**
- **Boxplots**: Compara√ß√£o de centralidades entre grafos
- **Barplots**: M√©tricas agregadas dos grafos
- **Rankings**: Top colaboradores por diferentes crit√©rios

**4. Dashboard Interativo**
```python
def create_dashboard(self, graphs: Dict[str, CollaborationGraph]):
    fig = make_subplots(rows=2, cols=2, subplot_titles=(...))
    # M√∫ltiplas visualiza√ß√µes em uma interface
```

---

## ‚öôÔ∏è Scripts Auxiliares

### **main.py**
**Fun√ß√£o**: Script principal que orquestra todo o pipeline

```python
def main():
    # 1. Configura√ß√£o e carregamento de vari√°veis
    load_dotenv()
    
    # 2. Extra√ß√£o ou carregamento de dados
    builder.extract_and_load_data() or builder.load_data_from_csv()
    
    # 3. Constru√ß√£o dos grafos
    builder.build_all_graphs()
    
    # 4. Exporta√ß√£o e visualiza√ß√£o
    builder.export_all_graphs()
    visualizer.create_dashboard()
```

### **complete_extraction.py**
**Fun√ß√£o**: Script de recupera√ß√£o para completar extra√ß√µes falhadas

**Funcionalidades:**
- Extrai apenas dados faltantes
- Reutiliza dados j√° extra√≠dos
- Tratamento espec√≠fico para rate limits

### **generate_sample_data.py**
**Fun√ß√£o**: Gerador de dados simulados para testes

**Gera:**
- Issues simuladas com metadados realistas
- PRs com informa√ß√µes de merge
- Coment√°rios e reviews distribu√≠dos estatisticamente
- Relacionamentos entre usu√°rios simulados

### **check_rate_limit.py**
**Fun√ß√£o**: Monitoramento do rate limit da API GitHub

```python
def check_rate_limit():
    response = requests.get("https://api.github.com/rate_limit", headers=headers)
    data = response.json()
    
    core = data['resources']['core']
    print(f"Requests restantes: {core['remaining']}")
    print(f"Reset em: {datetime.fromtimestamp(core['reset'])}")
```

---

## üìä Estruturas de Dados

### **Issues DataFrame**
```
Colunas: id, number, title, state, author, created_at, updated_at, 
         closed_at, closed_by, comments_count, is_pull_request
```

### **Pull Requests DataFrame**
```
Colunas: id, number, title, state, author, created_at, updated_at,
         closed_at, merged_at, merged_by, comments_count, 
         review_comments_count, commits_count, additions, deletions
```

### **Comments DataFrames**
```
Issue Comments: id, issue_number, author, created_at, updated_at, body_length
PR Comments: id, pr_number, author, created_at, type, body_length
```

### **Reviews DataFrame**
```
Colunas: id, pr_number, reviewer, state, submitted_at, body_length
```

---

## üîÑ Fluxo de Execu√ß√£o

### **Pipeline Completo:**

1. **Inicializa√ß√£o**
   - Carregamento de configura√ß√µes (.env)
   - Inicializa√ß√£o de classes principais

2. **Extra√ß√£o de Dados**
   - Requisi√ß√µes paginadas √† API GitHub
   - Tratamento de rate limits
   - Persist√™ncia em CSV

3. **Processamento**
   - Limpeza e normaliza√ß√£o dos dados
   - Filtros por tipo de intera√ß√£o
   - Constru√ß√£o de relacionamentos

4. **Modelagem de Grafos**
   - Cria√ß√£o de n√≥s (usu√°rios)
   - Cria√ß√£o de arestas (intera√ß√µes)
   - Atribui√ß√£o de pesos

5. **An√°lise**
   - C√°lculo de m√©tricas de centralidade
   - Estat√≠sticas descritivas
   - Identifica√ß√£o de padr√µes

6. **Visualiza√ß√£o**
   - Grafos de rede
   - Dashboards interativos
   - An√°lises comparativas

7. **Exporta√ß√£o**
   - JSON para an√°lises program√°ticas
   - GEXF para Gephi
   - HTML para visualiza√ß√£o web

---

## üßÆ Algoritmos Implementados

### **Centralidade de Grau**
```python
# In-degree: quantas intera√ß√µes o usu√°rio recebe
in_degree = graph.in_degree(node)

# Out-degree: quantas intera√ß√µes o usu√°rio faz
out_degree = graph.out_degree(node)
```

### **Centralidade de Proximidade**
```python
# Dist√¢ncia m√©dia inversa para todos os outros n√≥s
closeness = nx.closeness_centrality(graph)
```

### **Centralidade de Intermedia√ß√£o**
```python
# Frequ√™ncia do n√≥ nos caminhos mais curtos
betweenness = nx.betweenness_centrality(graph)
```

### **PageRank**
```python
# Import√¢ncia baseada na qualidade das conex√µes
pagerank = nx.pagerank(graph, alpha=0.85)
```

---

## ‚ö° Otimiza√ß√µes Implementadas

### **Performance**
- **Pagina√ß√£o eficiente**: Requisi√ß√µes em lotes de 100 itens
- **Caching**: Dados salvos em CSV para reutiliza√ß√£o
- **Subgrafos**: Visualiza√ß√£o apenas dos n√≥s mais relevantes
- **Lazy loading**: C√°lculos sob demanda

### **Robustez**
- **Error handling**: Try-catch em todas as requisi√ß√µes
- **Rate limiting**: Pausas autom√°ticas quando necess√°rio
- **Valida√ß√£o**: Verifica√ß√£o de integridade dos dados
- **Fallbacks**: Dados simulados quando API falha

### **Escalabilidade**
- **Modular**: Cada funcionalidade em classe separada
- **Configur√°vel**: Par√¢metros ajust√°veis via .env
- **Extens√≠vel**: F√°cil adi√ß√£o de novos tipos de grafo

---

## üéØ Casos de Uso

### **An√°lise de Comunidades**
- Identificar grupos de colaboradores frequentes
- Detectar n√∫cleos de desenvolvimento
- Mapear hierarquias de contribui√ß√£o

### **Detec√ß√£o de Influenciadores**
- Usu√°rios com alta centralidade
- Conectores entre diferentes grupos
- Especialistas em √°reas espec√≠ficas

### **Evolu√ß√£o Temporal**
- Tracking de mudan√ßas na rede
- Identifica√ß√£o de tend√™ncias
- Previs√£o de futuras colabora√ß√µes

### **Compara√ß√£o de Reposit√≥rios**
- Benchmarking entre projetos
- An√°lise de maturidade
- Padr√µes de governan√ßa

---

## üìà M√©tricas de Qualidade

### **Cobertura de C√≥digo**
- Tratamento de erros em 100% das requisi√ß√µes
- Valida√ß√£o de dados em todos os pontos
- Testes com dados simulados

### **Performance**
- M√°ximo de 5.000 requests/hora (com token)
- Processamento de 1000+ issues em < 30 minutos
- Visualiza√ß√£o de grafos com 50+ n√≥s em tempo real

### **Usabilidade**
- Configura√ß√£o via arquivos .env
- Outputs em m√∫ltiplos formatos
- Documenta√ß√£o completa e exemplos

Este README t√©cnico fornece uma vis√£o abrangente de toda a implementa√ß√£o, desde as bibliotecas utilizadas at√© os algoritmos espec√≠ficos implementados para an√°lise de grafos de colabora√ß√£o.